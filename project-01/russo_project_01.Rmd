---
title: "Mini-Project 01"
output: 
  html_document:
    keep_md: true
    toc: true
    toc_float: true
---

# Data Visualization Project 01

```{r message=FALSE}
library(tidyverse)
library(scales)
summer_songs <- read_csv("../data/all_billboard_summer_hits.csv")
head(summer_songs)
```
# Dataset Summaries

The cells below represent some of the dataset exploration done using dplyr functions, with their data potentially being used in visualization generation.
The annotated report starts in the Dataset Visualization section.

Most interesting dataset attributes concern the following:

- **danceability**: How well a song is suited for dancing to (no style specified)
- **energy**: Possible aggregate attribute of how intense a long is (louder, faster tempo)
- **key**: Musical key the song is in
- **loudness**: How loud a song is in relation to its maximum level (0 dB)
- **mode**: Track modality (Minor or Major)
- **speechiness**: Degree of speech in a track, with 0.0 being lower
- **acousticness**: Scale of 0-1 on how acoustic a track is (0 being electric or electronic music like rock)
- **instrumentalness**: Likelihood the track contains any vocals (1.0 meaning vocals are unlikely)
- **liveness**: Determines if an audience is present in the recording
- **valence**: Happiness of a song, with 1.0 being happier
- **tempo**: Estimated tempo of a track in BPM
- **duration**: Track length in milliseconds
- **time_signature**: Overall time signature of a track (number of beats in bar)
- **year**: Year the track was released

For grouping, playlist_name, artist_name, and album_name may be of interest.

For visualizations, I would like to look at:
1. scatterplot of loudness, energy over year
2. scatterplot of danceability, loudness, tempo
3. scatterplot of danceability, duration, valence, acousticness,  over year
4. Barchart of modality and key
5. Boxplot of valence, modality and key
6. Bar chart of artists who charted the most

```{r}
# Basic dataset summary
summary(summer_songs)
```

```{r}
# Cell to produce a random sample of 5 songs in major/minor mode
# Songs in major mode are deemed as happier and more upbeat (Uptown Funk)
# Songs in minor mode as deemed as sadder or more serious (Hotel California)

# Example Songs in a Major Key
summer_songs %>%
  filter(mode == "major") %>% 
  select(track_name, artist_name, mode, valence, energy) %>%
  slice_sample(n = 5, replace = TRUE) %>% 
  print()

# Example Songs in a Minor Key
summer_songs %>%
  filter(mode == "minor") %>% 
  select(track_name, artist_name, mode, valence, energy) %>%
  slice_sample(n = 5, replace = TRUE) %>% 
  print()
```


```{r}
# Songs get louder each year
cor(summer_songs$loudness, summer_songs$year)

# Louder songs have more energy
cor(summer_songs$loudness, summer_songs$energy)

# Loudness increases danceability a little
cor(summer_songs$loudness, summer_songs$danceability)

# Duration has minor increase on danceability
cor(summer_songs$duration_ms, summer_songs$danceability)

# Faster songs are harder to dance to
cor(summer_songs$tempo, summer_songs$danceability)

# Sadder songs use more acoustics
cor(summer_songs$valence, summer_songs$acousticness)

# People talk less in more acoustic songs
cor(summer_songs$speechiness, summer_songs$acousticness)
```

```{r}
numeric_cols <- summer_songs %>% 
  select(where(is.numeric))

correlation_matrix <- cor(numeric_cols, use = "pairwise.complete.obs")

year_correlations <- correlation_matrix[, "year"]

sorted_year_correlations <- year_correlations[order(year_correlations, decreasing = TRUE)]

# Correlations with year
print(sorted_year_correlations[names(sorted_year_correlations) != "year"])
```

```{r}
# Cell to get top 5 songs per category of interest
# First block are 5 songs with highest values
# Second block are 5 songs with lowest values

# --- Energy ---
summer_songs %>%
  select(track_name, artist_name, energy) %>%
  slice_max(order_by = energy, n = 5) %>%
  print()

summer_songs %>%
  select(track_name, artist_name, energy) %>%
  slice_min(order_by = energy, n = 5) %>%
  print()

# --- Valence (Happiness) ---
summer_songs %>%
  select(track_name, artist_name, valence) %>%
  slice_max(order_by = valence, n = 5) %>%
  print()

cat("Tracks with low valence sound more negative (e.g., sad, depressed, angry).\n")
summer_songs %>%
  select(track_name, artist_name, valence) %>%
  slice_min(order_by = valence, n = 5) %>%
  print()

# --- Acousticness ---
summer_songs %>%
  select(track_name, artist_name, acousticness) %>%
  slice_max(order_by = acousticness, n = 5) %>%
  print()

summer_songs %>%
  select(track_name, artist_name, acousticness) %>%
  slice_min(order_by = acousticness, n = 5) %>%
  print()

# --- Danceability ---
summer_songs %>%
  select(track_name, artist_name, danceability) %>%
  slice_max(order_by = danceability, n = 5) %>%
  print()

summer_songs %>%
  select(track_name, artist_name, danceability) %>%
  slice_min(order_by = danceability, n = 5) %>%
  print()

# --- Loudness ---
summer_songs %>%
  select(track_name, artist_name, loudness) %>%
  slice_max(order_by = loudness, n = 5) %>%
  print()

summer_songs %>%
  select(track_name, artist_name, loudness) %>%
  slice_min(order_by = loudness, n = 5) %>%
  print()
```

```{r}
# Cell to get song counts by key and mode
summer_songs_key_count <- summer_songs %>%
  group_by(mode, key) %>%
  count(key)
  
summer_songs_key_count
```


```{r}
# Cell to find popular artists who might've charted multiple times
top_artists <- summer_songs %>%
  group_by(artist_name) %>%
  summarise(hit_count = n()) %>%
  arrange(desc(hit_count)) %>%
  slice_head(n = 10)

top_artists
```


# Data Visualizations

> Everybody wants to be a rockstar!

Well, maybe not everyone, but musical fame is seen by many as a ticket to freewheeling success and wealth. This begs the question, is there something to glean from the Billboard summer hits list over the past several decades? Are there any key takeaways from how music has changed in that time? Takeaways that we could potentially apply to our own musical endeavors? That is something this project seeks to determine, and we start by visualizing the correlation between several numerical attributes and year in a Lollipop chart, shown below:

```{r}
# Get correlation values into a dataframe
year_correlations <- data.frame(
  attribute = names(sorted_year_correlations),
  correlation = as.numeric(sorted_year_correlations)
)

# Lollipop chart showing the correlation values against year
ggplot(year_correlations %>% filter(attribute != "year"), aes(
  x= reorder(attribute, -correlation),
  y = correlation,
  color= reorder(attribute, -correlation)
)) +
  geom_pointrange(
    aes(ymin=0, ymax=correlation),
    linewidth = 1,
    size = 0.75) +
  scale_y_continuous(limits=c(-1, 1)) +
  labs(x = "", y = "", color = "Attribute", title="Attribute Correlation with Year", caption = "Source: all_billboard_summer_hits.csv",) +
  theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())
```

We see from the chart, that loudness is moderately, positively correlated with year, followed by energy, duration, danceability and speechiness. Liveness and tempo are weak, negatively correlated with year, followed by instrumentalness and valence, with acousticness moderately, negatively correlated with year.
From this, we can determine that songs have gotten louder, more energetic, longer, more danceable, and contain more vocals year over year.
Liveness and tempo haven't changed too much, while valence and instrumentalness have seen a decrease, and acousticness has seen a larger fall-off.
Let's visualize the relationship between loudness and year, with energy, in a scatterplot, as shown below:

```{r}
# Cell to visualize song loudness over year
p1_scatterplot <- ggplot(summer_songs, aes(
  x = year,
  y = loudness
)) + 
  geom_point(aes(color = energy)) + 
  geom_smooth(method="loess", se=FALSE) + 
  scale_x_continuous(breaks = breaks_width(10), limits=c(1958, 2020)) +
  scale_y_continuous(labels = label_number(suffix=" dB")) +
  labs(
    title = "Song Loudness by Year, colored by Energy, across Mode",
    caption = "Source: all_billboard_summer_hits.csv",
    y="",
    x="",
    color = "Energy"
  ) +
  facet_wrap(~ mode, labeller = as_labeller(c(`minor`="Minor", `major`="Major")))

ggsave(
  filename="../figures/p1-scatterplot.png",
  plot = p1_scatterplot,
  width = 8,
  height = 6,
  dpi = 300
)

p1_scatterplot
```

The scatterplot shows loudness across year, with the points colored by energy, and the charts faceted by mode. We can see for songs in Major mode, there has been a consistent increase in loudness over the years, alongside louder songs tending to have a higher energy. For songs in Minor mode, we can see a dip in loudness in the 70s and 80s, before loudness increases throughout the 90s-2010, before beginning to decrease again. This is interesting, and indicates that modern songs are much louder than their older counterparts. Let's visualize loudness in relation to other positively correlated attributes, such as danceability, in the scatterplot below:


```{r}
# Cell to visualize song danceability in relation to loudness,and tempo
ggplot(summer_songs, aes(
  x = loudness,
  y = danceability
)) + 
  geom_point(aes(color = tempo)) + 
  geom_smooth(method="lm", se=FALSE) +
  scale_x_continuous(labels = label_number(suffix=" dB")) +
  labs(
    title = "Song Danceability in relation to Loudness, colored by Tempo",
    caption = "Source: all_billboard_summer_hits.csv",
    y="Danceability",
    x="",
    color = "Tempo",
  )
```

The scatterplot shows song danceability in relation to loudness, colored by tempo. we can see an increase in danceability as the songs get louder, but there isn't a clear relationship for tempo in the graph. Most points seem to trend towards having a tempo somewhere in the ~100 range, which does make some sense. Faster songs are harder to dance to, and the same could be said for songs that are too slow. Let's take this visualization further by examining danceability in relation to duration, showing in the bubble chart below:

```{r}
# scatterplot to examine danceability and duration alongside energy and acousticness

ggplot(summer_songs, aes(
  x = duration_ms,
  y = danceability,
  color = acousticness
)) + 
  geom_point() + 
  #geom_smooth(method="loess", se=FALSE) +
  scale_x_continuous(labels = function(x) x/1000) +
  labs(
    title = "Song Danceability in relation to Duration, colored by Acousticness",
    x = "Duration (seconds)",
    y = "Danceability",
    color = "Acousticness",
    caption = "Source: all_billboard_summer_hits.csv",
  )
```

Well, while this was **originally** a bubble chart, I revised and simplified this visualization to remove sizing the points based on acousticness, preferring to move the acousticness variable to the color aesthetic, and omitting valence entirely as it's explored in later visualizations. With the points colored by acousticness, we can see a similar pattern to the original visualization, in that duration doesn't seem to impact danceability to a great degree, with most songs landing around the 200-250 second duration range, with varying degrees of danceability. While not included in the final plot, we can verify this with geom_smooth(), as with method=lm there appears to be a weakly positive correlation. However, with method=loess,we can see an uptick in danceability around 200-250 seconds due to most songs being clustered there, with a gradual regression as duration increases.

One area of clarity this scatterplot brings is that in the original bubble chart, I had noticed clusters that were more pronounced than they were in the current scatterplot. A cluster of songs still seems to form around ~220 seconds with a danceability of ~0.7, but we can see here that the acoustic and non-acoustic song clusters seem to overlap each other, with a greater number of acoustic songs being more spread out across duration as opposed to the acoustic songs.

Still, if we want to go with the flow and land within the general cluster of songs, it is most important to make a song with a duration between 200-250 seconds. Acousticness doesn't matter as much as originally thought, but most songs within the 200-250 second range appear to have a lower acousticness, which is something to keep in mind. Another important topic to consider is what key our song should be in, a topic visualized in the bar chart below:

```{r}
#Bar chart here showing count of songs in each key, per mode
ggplot(summer_songs_key_count, aes(
  x = key,
  y = n
)) + 
  geom_col() +
  labs(
    title = "Song count per Key, across Mode",
    y= "Count",
    x = "Key",
    caption = "Source: all_billboard_summer_hits.csv",
  ) +
  facet_wrap(~ mode, labeller = as_labeller(c(`minor`="Minor", `major`="Major")))

```

We can see that more songs are done in Major mode as opposed to Minor mode, and the greatest count of songs are done in the C, C#, and G keys, in the Major mode. From this, it can be assumed that we should perform our songs in the major mode, in any one of the aforementioned keys. However, we need to ask ourselves if we want the song to be happy or sad. To answer this, let's visualize the valence distribution of each key, by their mode, as shown in the boxplot below:

```{r fig.width=9}
# Boxplot showing valence based on mode and key
ggplot(summer_songs, aes(
  x = key,
  y = valence,
  color = mode
)) + 
  geom_boxplot() +
  labs(
    title = "Valence Distribution per Key, colored by Mode",
    x = "Key",
    y = "Valence",
    color = "Mode",
    caption = "Source: all_billboard_summer_hits.csv",
  )
```

Instead of faceting, we opted to use color to show the different modes side by side. Major mode songs are generally considered happier, while minor mode songs are considered sadder. However, the boxplot shows a wide distribution of the valence across keys. Granted, the presence of more songs in some keys like C major can widen the distribution compared to some keys like D minor. And, considering these are the most popular songs for their summer season, it stands to reason with the general trends that sadder, less energetic songs in minor key may not chart as frequently, explaining minor key songs with higher valence as seen with D minor. However, we can see how the median valence varies across key, which allows us to pin where our song should land happiness-wise in the key and mode that we choose to perform it in. For example, if we want to play our song in G major, it appears we should have a valence of 0.7, while also keeping in mind the songs at the 25th percentile that have a valence just below 0.5.

So, let's say being original and factoring all of these audio features into our song is just too much work, is there an artist who charted multiple times that we can just emulate in the hopes of success? There is! And from the bar chart below, we can see that artist is...

```{r}
# Boxplot showing the top 10 artists with the most charts
ggplot(top_artists, aes(
  y =  reorder(artist_name, hit_count),
  x = hit_count
)) +
  geom_col() +
  labs(
    title = "Top 10 Charting Artists",
    x = "Hit Count",
    y="",
    fill = "Artist",
    caption = "Source: all_billboard_summer_hits.csv"
  )
```

Rihanna. If you want to be a rich and famous chart-topper, just emulate Rihanna.

Granted, it's a bit more nuanced than that, but the artists that are on this chart have songs that line up with what we uncovered across the earlier charts. Rihanna is a pop singer, and that genre is known for loud, energetic, happier songs with low acousticness (One song of hers that comes to mind, *Please Don't Stop the Music*). Below Rihanna we have Katy Perry, another pop singer (*Firework*). And below her we have an older artist, Elton John. Elton John being around for longer means he had more time to land chart toppers, but one song that comes to mind from him that fits the pattern we found is *I'm Still Standing*. The same could be said for some of the other older artists on this list like The Beatles (*Here Comes the Sun*), Donna Summer (*Last Dance*), and the Bee Gees (*Stayin Alive*). However, more contemporary artists with less time active such as Rihanna and Katy Perry, reinforce the patterns uncovered in our earlier visualizations.


# Mini-Project Report Wrapup

  From the annotated visualizations, we can surmise that to have the best chance at a chart topper, we should make a loud, energetic song with a stable tempo to make it more suitable for dancing. The song itself should have a lower acousticness and a duration between 200-250 seconds, with a varying degree of valence depending on the key and mode that we perform it in. If all else fails, we can try to emulate Rihanna or Katy Perry. However, success and fame is often much harder to hack than by boiling down the most popular entries to their base attributes. Songs can resonate with people for different reasons, and it can be argued that by trying to formulate a chart topping song, it could itself be formulaic. Ultimately, the takeaways uncovered in the notebook could be used to make a song that runs counter to them, or to help create a song based on attributes that a songwriter might find personally appealing. At the end of the day, we should make a song that we appreciate and enjoy, and if it overlaps with some of the qualities seen in the top songs then that's a bonus.

  Originally I planned to have a scatterplot, bar chart, and violin plot for this assignment. However, over time I added in more charts such as a bubble chart (revised to be a scatterplot), a lollipop chart, and replaced a violin plot with a regular boxplot, as the distribution of valence per key was viewable with just a normal boxplot. I knew a scatterplot would be necessary for comparing continuous attributes, a bar chart would be needed to show the count of some attributes per key or artist, and the lollipop chart would serve as an easier way to show correlation between all numeric attributes and year.

  The story I told was told over the course of the notebook visualizations, which was "how to formulate a chart topping song to get rich and famous in the music industry." Granted, there is a bit more nuance to the story, but we were able to show the qualities that songs possess in the modern day, and what attributes modern music listeners may want from the songs they choose to consume. However, any song we create should be something that we enjoy making and listening to at a baseline, and having it overlap with the most popular attributes is beneficial, but not mandatory. There is no point in a success built without passion or enjoyment.

  I applied the principles of data visualizations and design in a couple ways for this assignment, the first of which was keeping the graph themes consistent across my charts (repetition). I only needed to tweak the theme for the lollipop chart, where I removed the x axis text and ticks, and how I used a vibrant color palette to help distinguish between the different attributes. Contrast was employed with the scatterplots, with point color serving to show variables such as energy and tempo, and how they exist within the relationship between the x and y variables. Alignment and proximity were in mind when creating the visualizations, with some labels being considered redundant being removed to give a better sense of space/grouping, and with the general alignment not being tweaked outside of the default theme. I was also thinking of the readings, and how blank space and removing unneeded information can help improve the clarity of a plot. I also thought of the "ink to data" ratio on when/when not to use color on some of the visualizations, and sought to provide the most content with the least amount of fiddling.





